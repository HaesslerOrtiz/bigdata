{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d284f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Relacionar google drive con Collab, para poder usar mi drive como almacenamiento de archivos,\n",
    "y como lugar donde van a reposar los outputs que se generen en este script.\n",
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount('/content/t3drive')\n",
    "# Ejecutar el código anterior y aceptar lo solicitado; permisos y accesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77af9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importación de paquetes módulos y funciones. Cabe aclarar que no es necesario importarlas\n",
    "todos al inicio, solo que es una práctica heredada de la codificación tradicional que ayuda\n",
    "a ser mas eficiente la compilación del código así como su lectura.\n",
    "'''\n",
    "import os # Para interactuar con el sistema operativo (rutas de archivos, crear directorios)\n",
    "import pandas as pd # Para manipulación y análisis de datos (DataFrames)\n",
    "import matplotlib.pyplot as plt # Para crear visualizaciones estáticas (gráficos)\n",
    "import seaborn as sns # Para crear visualizaciones estadísticas atractivas, basado en matplotlib\n",
    "from sklearn.model_selection import train_test_split # Para dividir datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.linear_model import LogisticRegression # Implementación del modelo de Regresión Logística\n",
    "from sklearn.metrics import accuracy_score, classification_report # Métricas para evaluar modelos de clasificación (precisión, informe de clasificación)\n",
    "from sklearn.tree import DecisionTreeClassifier # Implementación del modelo de Árbol de Decisión\n",
    "from sklearn.model_selection import GridSearchCV # Para ajuste de hiperparámetros utilizando búsqueda en cuadrícula y validación cruzada\n",
    "from sklearn.neighbors import KNeighborsClassifier # Implementación del modelo k-NN (K-Nearest Neighbors)\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f722827",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definir las rutas para guardar las figuras, tablas y notebooks.\n",
    "'''\n",
    "\n",
    "# Definir las rutas base\n",
    "base = '/content/t3drive/MyDrive/taller3'\n",
    "figs = os.path.join(base, 'figures')\n",
    "codes = os.path.join(base, 'codes')\n",
    "\n",
    "# Crear las rutas sino existen\n",
    "os.makedirs(figs, exist_ok=True)\n",
    "os.makedirs(codes, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad85c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1.1: Cargar los datos y convertirlos en un \"Dataframe\". Tener en cuenta que se encuentran en un archivo Excel.\n",
    "'''\n",
    "\n",
    "# Ruta completa hacia el los datos alojados en mi drive\n",
    "file_path = os.path.join(base, \"adult_data.xlsx\")\n",
    "\n",
    "# Leer la primera hoja del Excel (sheet 0)\n",
    "import pandas as pd\n",
    "df = pd.read_excel(file_path, sheet_name=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de6dd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1.2: Mostrar la forma del \"Dataframe y mostrar primeros 5 registros.\n",
    "'''\n",
    "print(\"Forma del dataset:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050b2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1.3: Mostrar tipos de datos de cada columna\n",
    "'''\n",
    "print(\"Tipos de datos por columna:\\n\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa1beb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1.4: Generar estadisticas descriptivas para las caracteristicas numericas con un formato adecuado.\n",
    "'''\n",
    "print(\"\\nEstadísticas descriptivas para características numéricas:\\n\")\n",
    "\n",
    "# Gnerar estadísticas descriptivas\n",
    "descriptive_stats = df.describe()\n",
    "\n",
    "# Aplicar formato al Dataframe\n",
    "styled_stats = descriptive_stats.style.format(\"{:,.2f}\")\n",
    "display(styled_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "442fd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1.5: Usar técnicas de visualización para explorar la distribución de características numéricas e\n",
    "identificar posibles valores atípicos y guardar las figuras.\n",
    "'''\n",
    "\n",
    "# Seleccionar solo las columnas numéricas\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Iterar sobre las columnas numéricas y generar histogramas y boxplots\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\nVisualizando la distribución de '{col}':\")\n",
    "\n",
    "    # Histograma\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Histograma de {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    histogram_path = os.path.join(figs, f'histogram_{col}.png')\n",
    "    plt.savefig(histogram_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot (vertical)\n",
    "    plt.figure(figsize=(5, 10)) # Ajustar el tamaño de la figura para la orientaciuón vertical\n",
    "    sns.boxplot(y=df[col]) # Cambiar x a y para la orientación vertical\n",
    "    plt.title(f'Boxplot de {col}')\n",
    "    plt.ylabel(col) # Cambiar xlabel a ylabel\n",
    "    boxplot_path = os.path.join(figs, f'boxplot_{col}.png')\n",
    "    plt.savefig(boxplot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9797b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1.6: Analizar la distribución de la variable objetivo \"income\".\n",
    "'''\n",
    "\n",
    "# Inspección previa porque parece que hay mas de dos categorías en esta variable\n",
    "print(\"Etiquetas únicas crudas en 'income':\")\n",
    "print(sorted(df['income'].astype(str).unique()))\n",
    "\n",
    "# Limpieza robusta de la columna 'income\n",
    "# - pasa a str\n",
    "# - strip de espacios\n",
    "# - elimina puntos al final (caso '...K.')\n",
    "# - normaliza mayúsculas/minúsculas todo a minusculas\n",
    "# - colapsa espacios internos\n",
    "income_clean = (df['income'].astype(str)\n",
    "                .str.strip()\n",
    "                .str.replace(r'\\.$', '', regex=True)   # elimina punto final\n",
    "                .str.replace(r'\\s+', ' ', regex=True)  # colapsa espacios\n",
    "                .str.lower())\n",
    "\n",
    "# Mapeo a dos únicas clases canónicas\n",
    "mapping = {\n",
    "    '<=50k': '<=50K',\n",
    "    '>50k': '>50K'\n",
    "}\n",
    "df['income'] = income_clean.map(mapping)\n",
    "\n",
    "# Si hay valores inesperados (como '?'), los dejamos como NaN para no contaminar\n",
    "unexpected = income_clean[~income_clean.isin(mapping.keys())].unique()\n",
    "if len(unexpected) > 0:\n",
    "    print(\"\\nValores inesperados tras limpieza (se convierten a NaN):\", sorted(unexpected))\n",
    "    # forzar NaN donde no calce con mapping\n",
    "    df.loc[~income_clean.isin(mapping.keys()), 'income'] = pd.NA\n",
    "\n",
    "# Opcional: convertir a categórica con orden definido\n",
    "df['income'] = pd.Categorical(df['income'], categories=['<=50K', '>50K'], ordered=True)\n",
    "\n",
    "# Conteos finales\n",
    "print(\"\\nDistribución final de 'income':\")\n",
    "print(df['income'].value_counts(dropna=False))\n",
    "\n",
    "# Histograma variable \"income\"\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.countplot(x='income', data=df, order=['<=50K', '>50K'])\n",
    "plt.title('Distribución de la variable objetivo: income')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Conteo')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Guardar figura en la carpeta definida\n",
    "# Si el archivo ya existe, será reemplazado automáticamente)\n",
    "plot_path = os.path.join(figs, \"income_distribution.png\")\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Mostrar en pantalla\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ab1d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q2.1: Verificar valores nulos y reportar el conteo y porcentaje de datos faltantes para cada columna.\n",
    "'''\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"Conteo de valores nulos por columna:\")\n",
    "null_counts = df.isnull().sum()\n",
    "display(null_counts)\n",
    "\n",
    "# Calcular el porcentaje de valores nulos\n",
    "print(\"\\nPorcentaje de valores nulos por columna:\")\n",
    "null_percentages = (null_counts / len(df)) * 100\n",
    "display(null_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdcfd5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q2.2: Verificar y eliminar filas duplicadas.\n",
    "'''\n",
    "\n",
    "# Verificar si hay filas duplicadas\n",
    "print(\"Número de filas duplicadas antes de la eliminación:\", df.duplicated().sum())\n",
    "\n",
    "# Eliminar filas duplicadas\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verificar si hay filas duplicadas después de la eliminación\n",
    "print(\"Número de filas duplicadas después de la eliminación:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f697d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q2.3: Manejo de valores faltantes usando estrategias de imputación y eliminación\n",
    "- Como se observo anteriormente, no hay valores nulos, por lo que no es necesario\n",
    "hacer ninguna acción de las sugeridas.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69121695",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q2.4: Definir la variable objetivo (aunque la verdad es innecesario, se puede apuntar\n",
    "a la columna income directamente).\n",
    "'''\n",
    "# La columna \"income\" es la variable objetivo para este análisis.\n",
    "# Representa si el ingreso de un individuo es <=50K o >50K.\n",
    "target_variable = 'income'\n",
    "print(f\"La variable objetivo definida es: {target_variable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74218923",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3.1: Dividir los datos en conjuntos de entrenamiento y prueba (proporción 80/20).\n",
    "'''\n",
    "\n",
    "# Definir las características (X) y la variable objetivo (y)\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "'''\n",
    "El parámetro stratify=y asegura que la división de los datos en conjuntos de entrenamiento y\n",
    "prueba mantenga aproximadamente la misma proporción de la variable objetivo (y) que la que\n",
    "existe en el conjunto de datos original.\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a87b3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3.2: Verificar el balance de la variable objetivo en los conjuntos de entrenamiento\n",
    "y prueba.\n",
    "Esto ya se garantizó un poco con el paso anterior, sin embargo, se puede confirmar\n",
    "realizando algunas impresiones.\n",
    "'''\n",
    "\n",
    "# Verificar la proporción de la variable objetivo en el conjunto de entrenamiento:\n",
    "print(\"Proporción de la variable objetivo en el conjunto de entrenamiento:\")\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "# Verificar la proporción de la variable objetivo en el conjunto de prueba:\n",
    "print(\"\\nProporción de la variable objetivo en el conjunto de prueba:\")\n",
    "display(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3c7f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3.3: Reportar el tamaño de los sets de entrenamiento y prueba.\n",
    "'''\n",
    "print(\"Forma del conjunto de entrenamiento (X_train):\", X_train.shape)\n",
    "print(\"Forma del conjunto de prueba (X_test):\", X_test.shape)\n",
    "print(\"Forma de las etiquetas de entrenamiento (y_train):\", y_train.shape)\n",
    "print(\"Forma de las etiquetas de prueba (y_test):\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7dc5471",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4.1: Calcular y visualizar la matriz de correlación entre las características numéricas y\n",
    "la variable objetivo, y guardar la figura.\n",
    "'''\n",
    "\n",
    "# Seleccionar solo las columnas numéricas del conjunto de entrenamiento\n",
    "numerical_cols_train = X_train.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Incluir la variable objetivo 'income' (ya limpia con 2 categorías) en el DataFrame para calcular la correlación\n",
    "# Asegurarnos de que 'income' sea numérica para el cálculo de correlación.\n",
    "# Podemos mapear las categorías a números (por ejemplo, <=50K a 0 y >50K a 1).\n",
    "income_numeric = y_train.map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "# Concatenar las características numéricas y la variable objetivo numérica\n",
    "df_train_corr = pd.concat([numerical_cols_train, income_numeric], axis=1)\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "# Excluir NaN que puedan haber surgido del mapeo (aunque con la limpieza previa no deberían haber)\n",
    "correlation_matrix = df_train_corr.corr().dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "# Visualizar la matriz de correlación usando un heatmap con colores invertidos\n",
    "plt.figure(figsize=(12, 10)) # Aumentar tamaño para incluir la nueva variable\n",
    "# Usar 'coolwarm_r' para que el azul sea positivo y el rojo negativo\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm_r', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Matriz de Correlación de Características Numéricas e Income')\n",
    "plt.tight_layout() # Ajustar para evitar que las etiquetas se superpongan\n",
    "\n",
    "# Definir la ruta para guardar la figura\n",
    "correlation_plot_path = os.path.join(figs, 'correlation_matrix_numerical_income.png')\n",
    "\n",
    "# Guardar la figura\n",
    "plt.savefig(correlation_plot_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70daf81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4.2: Visualizar las relaciones entre características numéricas y la variable objetivo\n",
    "usando scatter plots y guardar la figura.\n",
    "'''\n",
    "\n",
    "# Seleccionar solo las columnas numéricas\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Añadir la columna 'income' al DataFrame temporal para el pairplot\n",
    "df_plot = df[numerical_cols].copy()\n",
    "df_plot['income'] = df['income']\n",
    "\n",
    "# Crear scatter plots por pares de características numéricas, diferenciando por 'income'\n",
    "# Usar un subconjunto de columnas si hay muchas para evitar una matriz de plots demasiado grande\n",
    "if len(numerical_cols) > 6: # Limit to a reasonable number of columns for pairplot\n",
    "    print(\"Mostrando pairplot para un subconjunto de características numéricas debido a la cantidad.\")\n",
    "    cols_to_plot = numerical_cols[:6].tolist() + ['income']\n",
    "    g = sns.pairplot(df_plot[cols_to_plot], hue='income', palette='viridis')\n",
    "else:\n",
    "    g = sns.pairplot(df_plot, hue='income', palette='viridis')\n",
    "\n",
    "plt.suptitle('Scatter Plots de Características Numéricas por Nivel de Ingreso', y=1.02)\n",
    "plt.tight_layout(rect=[0, 0, 1, 1.02]) # Adjust layout to prevent suptitle overlap\n",
    "\n",
    "# Definir la ruta para guardar la figura\n",
    "pairplot_path = os.path.join(figs, 'pairplot_numerical_income.png')\n",
    "\n",
    "# Guardar la figura\n",
    "# Use g.fig to save the figure generated by seaborn's pairplot\n",
    "g.fig.savefig(pairplot_path, dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b58987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4.3: Con base en los hallazgos, seleccionar las tres variables discriminativas más prometedoras\n",
    "y construir una colección de clasificadores basados ​​en reglas utilizando predictores por pares.\n",
    "- De aceuerdo a lo que dejaron ver las anteriores gráficas, las variables elegidas fueron:\n",
    "- age\n",
    "- education-num\n",
    "- hours-per-week\n",
    "- capital-gain\n",
    "\n",
    "Q4.4: Para cada par de predictores, implemente un clasificador basado en reglas y evalúe su desempeño\n",
    "utilizando precisión, especificidad, sensibilidad y puntuación F1.\n",
    "\n",
    "Q4.5: Reportar el clasificador con mejor rendimiento y sus métricas de rendimiento.\n",
    "'''\n",
    "\n",
    "# Variables seleccionadas basadas en análisis previos\n",
    "selected_features = ['age', 'education-num', 'hours-per-week', 'capital-gain']\n",
    "target = 'income'\n",
    "\n",
    "# Diccionario para almacenar los clasificadores entrenados y su rendimiento\n",
    "classifiers = {}\n",
    "\n",
    "# Iterar a través de todos los pares posibles de las variables seleccionadas\n",
    "for i in range(len(selected_features)):\n",
    "    for j in range(i + 1, len(selected_features)):\n",
    "        feature1 = selected_features[i]\n",
    "        feature2 = selected_features[j]\n",
    "        pair = (feature1, feature2)\n",
    "\n",
    "        print(f\"\\nConstruyendo clasificador para las variables: {pair}\")\n",
    "\n",
    "        # Seleccionar las variables emparejadas para entrenamiento y prueba\n",
    "        X_train_pair = X_train[[feature1, feature2]]\n",
    "        X_test_pair = X_test[[feature1, feature2]]\n",
    "\n",
    "        # Inicializar y entrenar un modelo simple de Regresión Logística (como proxy basado en reglas)\n",
    "        # La Regresión Logística puede ser vista como el aprendizaje de un límite de decisión lineal, que puede interpretarse como una regla.\n",
    "        '''\n",
    "        Regresión Logística:\n",
    "        ¿Qué es? Es un algoritmo de clasificación utilizado para predecir la probabilidad de que una instancia\n",
    "        pertenezca a una clase particular.\n",
    "        - ¿Para qué sirve? Se usa comúnmente para problemas de clasificación binaria (dos clases), como predecir\n",
    "          si un correo es spam o no, o si un cliente comprará un producto.\n",
    "        - ¿Cómo funciona? A diferencia de la regresión lineal que predice un valor continuo, la regresión logística\n",
    "          utiliza una función sigmoide (o logística) para mapear cualquier valor de entrada a un valor entre 0 y 1.\n",
    "          Este valor se interpreta como la probabilidad de pertenecer a la clase positiva. Si la probabilidad es mayor\n",
    "          que un umbral (comúnmente 0.5), se clasifica como la clase positiva; de lo contrario, como la clase negativa.\n",
    "        En esencia, busca encontrar un límite de decisión lineal que mejor separe las clases en el espacio de características.\n",
    "        '''\n",
    "        model = LogisticRegression(random_state=42)\n",
    "        model.fit(X_train_pair, y_train)\n",
    "\n",
    "        # Realizar predicciones en el conjunto de prueba\n",
    "        y_pred = model.predict(X_test_pair)\n",
    "\n",
    "        # Evaluar el clasificador\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        print(f\"Precisión (Accuracy): {accuracy:.4f}\")\n",
    "        print(\"Informe de Clasificación:\")\n",
    "        print(report)\n",
    "\n",
    "        # Almacenar el modelo y su rendimiento\n",
    "        classifiers[pair] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'report': report\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b33ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5.1: Implementar un clasificador de Árbol de Decisión.\n",
    "Este modelo se utilizará para predecir la variable objetivo 'income'.\n",
    "Se entrenará con los datos de entrenamiento y se evaluará con los datos de prueba.\n",
    "\n",
    "Q5.2: Entrenar el arbol de decisión con los datos de entrenamiento.\n",
    "'''\n",
    "\n",
    "# Inicializar el clasificador de Árbol de Decisión\n",
    "# Se puede ajustar el parámetro max_depth para controlar la complejidad del árbol\n",
    "'''\n",
    "Árbol de Decisión:\n",
    "¿Qué es? Es un modelo de aprendizaje supervisado que se utiliza tanto para problemas de clasificación como de regresión.\n",
    "¿Para qué sirve? Crea un modelo de predicción construyendo una estructura de árbol basada en decisiones sobre las características de los datos.\n",
    "¿Cómo funciona? El árbol se construye dividiendo el conjunto de datos en subconjuntos más pequeños basándose en el valor de una característica.\n",
    "Este proceso se repite recursively en cada nodo hijo hasta que se cumple un criterio de parada (por ejemplo, la profundidad máxima del árbol,\n",
    "el número mínimo de muestras en un nodo, etc.). Las hojas del árbol representan las clases de salida (para clasificación) o valores (para regresión).\n",
    "'''\n",
    "\n",
    "# --- Inicio de la modificación para manejar variables categóricas ---\n",
    "\n",
    "# Preprocesar las características: Convertir variables categóricas a numéricas usando One-Hot Encoding\n",
    "# Aplicar a los conjuntos de entrenamiento y prueba por separado para evitar fuga de datos\n",
    "X_train_processed = pd.get_dummies(X_train)\n",
    "X_test_processed = pd.get_dummies(X_test)\n",
    "\n",
    "# Asegurarse de que los conjuntos de entrenamiento y prueba tengan las mismas columnas después del one-hot encoding\n",
    "# Esto maneja casos donde una categoría puede aparecer en el test set pero no en el train set (o viceversa)\n",
    "X_train_processed, X_test_processed = X_train_processed.align(X_test_processed, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# --- Fin de la modificación ---\n",
    "\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento preprocesados\n",
    "print(\"Entrenando el clasificador de Árbol de Decisión...\")\n",
    "dt_classifier.fit(X_train_processed, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba preprocesado\n",
    "y_pred_dt = dt_classifier.predict(X_test_processed)\n",
    "\n",
    "# Evaluar el clasificador\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "report_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(\"\\nEvaluación del clasificador de Árbol de Decisión:\")\n",
    "print(f\"Precisión (Accuracy): {accuracy_dt:.4f}\")\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(report_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58cfda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5.3: Experimentar con diferentes hiperparámetros del Árbol de Decisión\n",
    "utilizando GridSearchCV para encontrar la mejor combinación.\n",
    "\n",
    "Q5.4: Evaluar el desempéño del mejor modelo encontrado en el conjunto de prueba.\n",
    "'''\n",
    "\n",
    "'''\n",
    "Hiperparámetro:\n",
    "En el contexto del aprendizaje automático, un hiperparámetro es un parámetro cuyo valor se utiliza para controlar el proceso de aprendizaje en sí mismo.\n",
    "A diferencia de los parámetros del modelo (que se aprenden de los datos), los hiperparámetros se establecen antes de que comience el entrenamiento del modelo.\n",
    "Ejemplos para un Árbol de Decisión incluyen: max_depth, min_samples_split, criterion.\n",
    "Ajustar los hiperparámetros es crucial para optimizar el rendimiento del modelo y evitar el sobreajuste o subajuste.\n",
    "'''\n",
    "\n",
    "'''\n",
    "GridSearchCV:\n",
    "Es una técnica de optimización de hiperparámetros proporcionada por la librería scikit-learn.\n",
    "Funciona realizando una búsqueda exhaustiva sobre un conjunto predefinido de valores de hiperparámetros (una \"cuadrícula\").\n",
    "Para cada combinación de hiperparámetros en la cuadrícula, entrena y evalúa el modelo utilizando validación cruzada (cv).\n",
    "Finalmente, selecciona la combinación de hiperparámetros que obtuvo la mejor puntuación promedio (definida por el parámetro 'scoring') durante la validación cruzada.\n",
    "Es una forma sistemática de encontrar la mejor configuración de hiperparámetros dentro de un espacio de búsqueda definido.\n",
    "'''\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "# Experimentaremos con 'max_depth' y 'min_samples_split'\n",
    "param_grid = {\n",
    "    'max_depth': [None, 5, 10, 15, 20], # None significa sin límite de profundidad\n",
    "    'min_samples_split': [2, 5, 10, 20]\n",
    "}\n",
    "\n",
    "# Inicializar el clasificador de Árbol de Decisión\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "# 'estimator' es el modelo que queremos optimizar (DecisionTreeClassifier)\n",
    "# 'param_grid' es el diccionario con los hiperparámetros a probar y sus valores\n",
    "# 'cv' especifica el número de folds para la validación cruzada (por ejemplo, 5)\n",
    "# 'scoring' especifica la métrica a optimizar (por ejemplo, 'accuracy')\n",
    "# 'n_jobs=-1' usa todos los procesadores disponibles, acelerando la búsqueda\n",
    "grid_search = GridSearchCV(estimator=dt_classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Iniciando búsqueda de hiperparámetros con GridSearchCV...\")\n",
    "\n",
    "# Realizar la búsqueda en los datos de entrenamiento preprocesados\n",
    "# Usamos los datos preprocesados (X_train_processed) que incluyen el one-hot encoding\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Búsqueda de hiperparámetros completada.\")\n",
    "\n",
    "# Mostrar los mejores hiperparámetros encontrados\n",
    "print(\"\\nMejores hiperparámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Mostrar la mejor puntuación (accuracy) obtenida con esos hiperparámetros\n",
    "print(\"\\nMejor Accuracy (validación cruzada):\")\n",
    "print(f\"{grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluar el mejor modelo encontrado en el conjunto de prueba\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "y_pred_best_dt = best_dt_model.predict(X_test_processed)\n",
    "\n",
    "print(\"\\nEvaluación del mejor modelo en el conjunto de prueba:\")\n",
    "print(f\"Precisión (Accuracy) en el conjunto de prueba: {accuracy_score(y_test, y_pred_best_dt):.4f}\")\n",
    "print(\"Informe de Clasificación en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_pred_best_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ab762b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5.5: Seleccionar e identificar la configuración con mejor rendimiento\n",
    "en función de las métricas e informe de los hiperparámetros elegidos.\n",
    "'''\n",
    "\n",
    "# Los resultados de la búsqueda de hiperparámetros se almacenan en el objeto grid_search\n",
    "# que se definió y ejecutó en la celda anterior.\n",
    "\n",
    "# La mejor combinación de hiperparámetros se encuentra en .best_params_\n",
    "print(\"La mejor configuración de hiperparámetros encontrada es:\")\n",
    "display(grid_search.best_params_)\n",
    "\n",
    "# La mejor puntuación (accuracy) obtenida con esta configuración durante la validación cruzada\n",
    "print(\"\\nLa mejor precisión (Accuracy) durante la validación cruzada fue:\")\n",
    "print(f\"{grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Para ver el rendimiento del modelo con los mejores hiperparámetros en el conjunto de prueba,\n",
    "# ya lo calculamos y mostramos al final de la celda anterior (Q5.3).\n",
    "# Podemos volver a imprimirlo aquí para consolidar los resultados.\n",
    "\n",
    "# Acceder al mejor estimador (el modelo con los mejores hiperparámetros)\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba usando el mejor modelo\n",
    "y_pred_best_dt = best_dt_model.predict(X_test_processed)\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "accuracy_best_test = accuracy_score(y_test, y_pred_best_dt)\n",
    "report_best_test = classification_report(y_test, y_pred_best_dt)\n",
    "\n",
    "print(\"\\nEvaluación del mejor modelo en el conjunto de prueba:\")\n",
    "print(f\"Precisión (Accuracy) en el conjunto de prueba: {accuracy_best_test:.4f}\")\n",
    "print(\"Informe de Clasificación en el conjunto de prueba:\")\n",
    "print(report_best_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27231ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q6.1: El proceso 'One Hot Encoding' ya se realizó anteriormente\n",
    "Q6.2,3: Implementar un clasificador k-NN (K-Nearest Neighbors).\n",
    "Este modelo se utilizará para predecir la variable objetivo 'income'.\n",
    "Se entrenará con los datos de entrenamiento preprocesados y se evaluará\n",
    "con los datos de prueba preprocesados.\n",
    "'''\n",
    "\n",
    "# Inicializar el clasificador k-NN\n",
    "# Puedes ajustar el número de vecinos (n_neighbors)\n",
    "'''\n",
    "K-Nearest Neighbors (k-NN):\n",
    "- ¿Qué es? Es un algoritmo de clasificación y regresión no paramétrico simple.\n",
    "- ¿Para qué sirve? Se utiliza para predecir la clase de un punto de datos basándose en las clases de sus 'k' vecinos\n",
    "  más cercanos en el espacio de características.\n",
    "- ¿Cómo funciona? Para clasificar un nuevo punto, el algoritmo calcula su distancia a todos los puntos en el conjunto de entrenamiento.\n",
    "  Luego, selecciona los 'k' puntos más cercanos. La clase del nuevo punto se asigna por la mayoría de votos de sus 'k' vecinos más cercanos.\n",
    "  La elección del valor de 'k' es crucial.\n",
    "'''\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5) # Usamos un valor inicial de k=5\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento preprocesados\n",
    "print(\"Entrenando el clasificador k-NN...\")\n",
    "# Usamos los datos ya codificados\n",
    "knn_classifier.fit(X_train_processed, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba preprocesado\n",
    "print(\"Realizando predicciones con el clasificador k-NN...\")\n",
    "y_pred_knn = knn_classifier.predict(X_test_processed)\n",
    "\n",
    "# Evaluar el clasificador\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "print(\"\\nEvaluación del clasificador k-NN:\")\n",
    "print(f\"Precisión (Accuracy): {accuracy_knn:.4f}\")\n",
    "print(\"Informe de Clasificación:\")\n",
    "print(report_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7e00346",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q6.4: Experimentar con diferentes valores de k para el clasificador k-NN\n",
    "y evaluar el rendimiento en el conjunto de prueba.\n",
    "Q6.5 Informar el rendimiento para diferentes valores de k e identificar el k óptimo según las métricas.\n",
    "'''\n",
    "\n",
    "# Definir un rango de valores para k a experimentar\n",
    "# Puedes ajustar este rango según sea necesario\n",
    "k_values = range(1, 31) # Experimentaremos con k desde 1 hasta 30\n",
    "\n",
    "# Lista para almacenar la precisión para cada valor de k\n",
    "accuracy_scores = []\n",
    "\n",
    "print(\"Experimentando con diferentes valores de k para el clasificador k-NN...\")\n",
    "\n",
    "# Iterar sobre los valores de k\n",
    "for k in k_values:\n",
    "    # Inicializar el clasificador k-NN con el valor actual de k\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Entrenar el modelo con los datos de entrenamiento preprocesados\n",
    "    # Usamos los datos ya codificados (X_train_processed)\n",
    "    knn_classifier.fit(X_train_processed, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba preprocesado\n",
    "    y_pred_knn = knn_classifier.predict(X_test_processed)\n",
    "\n",
    "    # Evaluar el clasificador y almacenar la precisión\n",
    "    accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "    print(f\"k = {k}: Precisión (Accuracy) = {accuracy:.4f}\")\n",
    "\n",
    "# Visualizar la precisión en función de k\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_values, accuracy_scores, marker='o', linestyle='-')\n",
    "plt.title('Precisión del Clasificador k-NN vs. Valor de k')\n",
    "plt.xlabel('Valor de k (Número de Vecinos)')\n",
    "plt.ylabel('Precisión (Accuracy)')\n",
    "plt.xticks(k_values[::2]) # Mostrar etiquetas solo para algunos valores de k\n",
    "plt.grid(True)\n",
    "plt.tight_layout() # Ajustar el diseño\n",
    "\n",
    "# Definir la ruta y el nombre del archivo para guardar la figura\n",
    "# Usaremos la variable 'figs' definida anteriormente para la carpeta de figuras\n",
    "knn_k_plot_path = os.path.join(figs, 'knn_accuracy_vs_k.png')\n",
    "\n",
    "# Guardar la figura en la ruta especificada\n",
    "plt.savefig(knn_k_plot_path, dpi=300, bbox_inches='tight') # dpi=300 para buena resolución\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Identificar el mejor valor de k y su precisión\n",
    "best_k_index = accuracy_scores.index(max(accuracy_scores))\n",
    "best_k = k_values[best_k_index]\n",
    "best_accuracy = accuracy_scores[best_k_index]\n",
    "\n",
    "print(f\"\\nEl mejor valor de k encontrado es {best_k} con una precisión de {best_accuracy:.4f}\")\n",
    "print(f\"Figura de Precisión vs k guardada en: {knn_k_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d41f730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Guardar en mi drive los notebooks en formato .ipynb y .py.\n",
    "'''\n",
    "\n",
    "notebook_name = \"notebook_taller3\"\n",
    "\n",
    "# Ruta completa de salida en Drive\n",
    "ipynb_path = os.path.join(codes, f\"{notebook_name}.ipynb\")\n",
    "py_path = os.path.join(codes, f\"{notebook_name}.py\")\n",
    "\n",
    "# Ruta temporal para guardar el notebook actual antes de convertir\n",
    "temp_ipynb_path = \"/content/temp_notebook.ipynb\"\n",
    "\n",
    "# Guardar el notebook actual a una ruta temporal usando el comando mágico %notebook\n",
    "# Esto asegura que nbconvert tenga un archivo .ipynb específico para trabajar\n",
    "get_ipython().run_line_magic('notebook', temp_ipynb_path)\n",
    "\n",
    "\n",
    "# Guardar en Drive en formato .ipynb\n",
    "# Usar el archivo temporal guardado por %notebook\n",
    "!jupyter nbconvert --to notebook --output \"{ipynb_path}\" \"{temp_ipynb_path}\"\n",
    "\n",
    "# Guardar en Drive en formato .py\n",
    "# Usar el archivo temporal guardado por %notebook\n",
    "!jupyter nbconvert --to script   --output \"{py_path}\"    \"{temp_ipynb_path}\"\n",
    "\n",
    "# Opcional: Eliminar el archivo temporal después de la conversión\n",
    "# import os\n",
    "# os.remove(temp_ipynb_path)\n",
    "\n",
    "print(f\"Archivos guardados en Drive:\\n- {ipynb_path}\\n- {py_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b653378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q7.1: Construir un clasificador de votación mayoritaria que combine las predicciones\n",
    "de los tres clasificadores con mejor rendimiento encontrados hasta ahora.\n",
    "\n",
    "Los tres clasificadores con mejor rendimiento identificados son:\n",
    "1. Árbol de Decisión con hiperparámetros optimizados (max_depth=10, min_samples_split=20)\n",
    "2. k-NN con k óptimo (k=25, basado en la exploración)\n",
    "3. El mejor clasificador basado en reglas de los pares de variables (educacion-num, capital-gain)\n",
    "\n",
    "Para el clasificador basado en reglas, usamos una Regresión Logística como proxy.\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "print(\"Construyendo y evaluando el clasificador de votación mayoritaria...\")\n",
    "\n",
    "# --- 1. Entrenar/obtener el mejor Árbol de Decisión (ya entrenado en Q5.3) ---\n",
    "# best_dt_model = grid_search.best_estimator_ # Ya tenemos este modelo de la celda Q5.3\n",
    "\n",
    "# --- 2. Entrenar el k-NN con el mejor k encontrado (k=25) ---\n",
    "best_knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn_model.fit(X_train_processed, y_train)\n",
    "\n",
    "\n",
    "# --- 3. Entrenar el mejor clasificador basado en reglas (Regresión Logística con 'education-num' y 'capital-gain') ---\n",
    "# Identificar las variables del mejor clasificador basado en reglas\n",
    "best_rule_pair = ('education-num', 'capital-gain')\n",
    "\n",
    "# Seleccionar las variables correspondientes para entrenamiento y prueba\n",
    "X_train_rule = X_train_processed[list(best_rule_pair)] # Usar processed para consistencia\n",
    "X_test_rule = X_test_processed[list(best_rule_pair)]   # Usar processed para consistencia\n",
    "\n",
    "# Entrenar el modelo de Regresión Logística\n",
    "best_rule_model = LogisticRegression(random_state=42)\n",
    "best_rule_model.fit(X_train_rule, y_train)\n",
    "\n",
    "\n",
    "# --- Construir el clasificador de votación mayoritaria ---\n",
    "# Definir los estimadores a incluir en el VotingClassifier\n",
    "# Los nombres ('dt', 'knn', 'rule') son etiquetas para identificar los modelos\n",
    "estimators = [\n",
    "    ('dt', best_dt_model),\n",
    "    ('knn', best_knn_model),\n",
    "    ('rule', best_rule_model)\n",
    "]\n",
    "\n",
    "# Inicializar el VotingClassifier\n",
    "# 'voting='hard'' significa votación mayoritaria (la clase predicha es la que recibe más votos)\n",
    "# 'n_jobs=-1' usa todos los procesadores disponibles\n",
    "ensemble_classifier = VotingClassifier(estimators=estimators, voting='hard', n_jobs=-1)\n",
    "\n",
    "# Entrenar el clasificador de conjunto con los datos de entrenamiento preprocesados\n",
    "# El VotingClassifier entrenará cada modelo individualmente\n",
    "print(\"Entrenando el clasificador de conjunto (VotingClassifier)...\")\n",
    "# Usar los datos preprocesados, que son necesarios para DT y k-NN,\n",
    "# y las columnas relevantes para el modelo de reglas se seleccionarán internamente si se pasa X_train_processed completo.\n",
    "# Opcionalmente, podrías crear un Pipeline con preprocesamiento, pero para simplicidad aquí\n",
    "# asumimos que los modelos individuales saben cómo manejar las columnas relevantes de X_train_processed.\n",
    "# Sin embargo, dado que el modelo 'rule' solo usa dos columnas, debemos asegurar que reciba solo esas.\n",
    "# Una forma robusta es pasar X_train_processed completo y el modelo 'rule' debe manejarlo.\n",
    "# Vamos a asegurar que los modelos en el ensemble trabajen con las mismas features que fueron entrenados individualmente.\n",
    "# Esto implica que si un modelo individual fue entrenado con X_train_processed, el ensemble debe recibir X_train_processed.\n",
    "\n",
    "# Es crucial que todos los modelos en el ensemble se entrenen y predigan usando el mismo conjunto de características.\n",
    "# Como best_dt_model y best_knn_model fueron entrenados con X_train_processed, el ensemble debe ser entrenado con X_train_processed.\n",
    "# El modelo 'rule' también debe ser compatible con la forma de X_train_processed o se debe usar un pipeline.\n",
    "# Dado que LogisticRegression puede manejar subconjuntos de columnas, y fue entrenado con un subconjunto,\n",
    "# podríamos tener un problema aquí si el ensemble pasa el X_train_processed completo.\n",
    "# Para ser más rigurosos, deberíamos re-entrenar el modelo de reglas dentro del ensemble o usar un pipeline.\n",
    "# Por ahora, para simplificar y mantener la estructura actual, re-entrenaremos los modelos en el ensemble.\n",
    "\n",
    "# Re-entrenar los modelos individuales con los datos preprocesados antes de construir el ensemble\n",
    "# (Aunque best_dt_model y best_knn_model ya lo están, esto asegura consistencia si se ejecuta esta celda sola)\n",
    "\n",
    "# Re-entrenar best_dt_model\n",
    "best_dt_model_ensemble = DecisionTreeClassifier(max_depth=grid_search.best_params_['max_depth'],\n",
    "                                                min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                                                random_state=42)\n",
    "best_dt_model_ensemble.fit(X_train_processed, y_train)\n",
    "\n",
    "# Re-entrenar best_knn_model\n",
    "best_knn_model_ensemble = KNeighborsClassifier(n_neighbors=best_k)\n",
    "best_knn_model_ensemble.fit(X_train_processed, y_train)\n",
    "\n",
    "# Re-entrenar best_rule_model (Regresión Logística) con el subconjunto de columnas\n",
    "best_rule_model_ensemble = LogisticRegression(random_state=42)\n",
    "best_rule_model_ensemble.fit(X_train_processed[list(best_rule_pair)], y_train) # Entrenar solo con las columnas relevantes\n",
    "\n",
    "\n",
    "# Actualizar la lista de estimadores con los modelos re-entrenados\n",
    "estimators_ensemble = [\n",
    "    ('dt', best_dt_model_ensemble),\n",
    "    ('knn', best_knn_model_ensemble),\n",
    "    ('rule', best_rule_model_ensemble)\n",
    "]\n",
    "\n",
    "# Inicializar el VotingClassifier con los modelos re-entrenados\n",
    "ensemble_classifier = VotingClassifier(estimators=estimators_ensemble, voting='hard', n_jobs=-1)\n",
    "\n",
    "# Entrenar el clasificador de conjunto\n",
    "# Aquí es donde está el detalle: el VotingClassifier espera X_train y X_test con las mismas columnas\n",
    "# para todos los estimadores, a menos que se usen pipelines.\n",
    "# Dado que nuestro modelo 'rule' fue entrenado solo con dos columnas, pasar X_train_processed completo fallará.\n",
    "# La forma más correcta es usar Pipelines o asegurar que todos los modelos manejen el mismo input.\n",
    "\n",
    "# --- Estrategia Corregida: Crear Pipelines para cada modelo si necesitan preprocesamiento específico ---\n",
    "# Sin embargo, dado que X_train_processed ya contiene todas las columnas one-hot encoded,\n",
    "# los modelos DT y k-NN pueden usarlas directamente. El modelo de reglas (LR) solo necesita 2 de esas columnas.\n",
    "\n",
    "# Opción 1: Modificar el modelo de reglas para que pueda aceptar X_train_processed completo y solo usar las columnas que necesita.\n",
    "# Esto requeriría un wrapper o un Pipeline.\n",
    "\n",
    "# Opción 2: Entrenar el VotingClassifier con X_train_processed completo, asumiendo que cada estimador\n",
    "# puede seleccionar las columnas que necesita. Esto NO es el comportamiento por defecto de sklearn estimators.\n",
    "\n",
    "# Opción 3 (La más robusta en sklearn): Usar ColumnTransformer dentro de un Pipeline si los modelos individuales\n",
    "# necesitan diferentes subconjuntos de columnas o preprocesamientos. Esto es más complejo.\n",
    "\n",
    "# --- Volvamos a la estrategia simple pero asegurándonos de que la entrada al VotingClassifier sea consistente ---\n",
    "# Los modelos DT y k-NN usan X_train_processed. El modelo de reglas usa X_train_processed[list(best_rule_pair)].\n",
    "# El VotingClassifier requiere que todos los estimadores en 'estimators' acepten el mismo input (X_train_processed).\n",
    "# El modelo de reglas actual (LogisticRegression) no aceptará X_train_processed completo porque fue entrenado solo con 2 columnas.\n",
    "\n",
    "# Para que funcione, el modelo de reglas dentro del VotingClassifier *debe* aceptar X_train_processed como input.\n",
    "# Una forma de lograr esto sin Pipelines complejos es crear un \"adaptador\" o simplemente\n",
    "# asegurar que el modelo de reglas dentro del ensemble pueda manejar el input completo.\n",
    "# La forma más sencilla aquí, dado el contexto, es re-definir el modelo de reglas para que acepte todas las columnas\n",
    "# pero solo use las que necesita. Esto generalmente se hace con un Pipeline que selecciona las columnas primero.\n",
    "\n",
    "# --- Vamos a implementar una versión simplificada usando una función que crea el modelo de reglas con selección de columnas ---\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Crear un Pipeline para el modelo de reglas que primero selecciona las columnas\n",
    "rule_pipeline = Pipeline([\n",
    "    ('selector', ColumnTransformer([('passthrough', 'passthrough', list(best_rule_pair))],\n",
    "                                  remainder='drop')), # Selecciona solo las columnas del par\n",
    "    ('model', LogisticRegression(random_state=42))   # Aplica la regresión logística\n",
    "])\n",
    "\n",
    "# Ahora, este rule_pipeline puede aceptar X_train_processed completo y solo usará las columnas correctas.\n",
    "\n",
    "# Actualizar la lista de estimadores con el pipeline de reglas\n",
    "estimators_ensemble_piped = [\n",
    "    ('dt', best_dt_model_ensemble), # DT ya entrenado con X_train_processed\n",
    "    ('knn', best_knn_model_ensemble), # k-NN ya entrenado con X_train_processed\n",
    "    ('rule_pipe', rule_pipeline)      # Pipeline de reglas que maneja X_train_processed\n",
    "]\n",
    "\n",
    "# Inicializar el VotingClassifier con los modelos y el pipeline de reglas\n",
    "ensemble_classifier = VotingClassifier(estimators=estimators_ensemble_piped, voting='hard', n_jobs=-1)\n",
    "\n",
    "# Entrenar el clasificador de conjunto con los datos de entrenamiento preprocesados\n",
    "# Ahora sí, pasamos X_train_processed completo al ensemble_classifier\n",
    "print(\"Entrenando el clasificador de conjunto (VotingClassifier) con Pipelines...\")\n",
    "ensemble_classifier.fit(X_train_processed, y_train)\n",
    "\n",
    "print(\"Entrenamiento del clasificador de conjunto completado.\")\n",
    "\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba preprocesado\n",
    "print(\"Realizando predicciones con el clasificador de votación mayoritaria...\")\n",
    "y_pred_ensemble = ensemble_classifier.predict(X_test_processed)\n",
    "\n",
    "# Evaluar el clasificador de conjunto\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
    "\n",
    "print(\"\\nEvaluación del clasificador de votación mayoritaria:\")\n",
    "print(f\"Precisión (Accuracy) en el conjunto de prueba: {accuracy_ensemble:.4f}\")\n",
    "print(\"Informe de Clasificación en el conjunto de prueba:\")\n",
    "print(report_ensemble)\n",
    "\n",
    "# Opcional: Comparar con los modelos individuales (ya lo tenemos de celdas anteriores)\n",
    "print(\"\\nComparación con los modelos individuales:\")\n",
    "print(f\"- Árbol de Decisión (Optimizado): Precisión = {accuracy_best_test:.4f}\")\n",
    "print(f\"- k-NN (Mejor k={best_k}): Precisión = {best_accuracy:.4f} (Note: Esta es la precisión en el test set del modelo individual, no del cross-validation)\")\n",
    "# Para el modelo de reglas individual, recuperamos su precisión del diccionario classifiers\n",
    "best_rule_accuracy_individual = classifiers[best_rule_pair]['accuracy']\n",
    "print(f\"- Regresión Logística (Pair: {best_rule_pair}): Precisión = {best_rule_accuracy_individual:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8affa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the different test sizes for the train-test splits.\n",
    "# This corresponds to train sizes of 60%, 40%, 20%, and 10% respectively.\n",
    "split_ratios = [0.6, 0.4, 0.2, 0.1]\n",
    "\n",
    "print(\"Different train-test split ratios (represented by test size):\")\n",
    "print(split_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ac66311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the performance metrics for each split ratio.\n",
    "results = {}\n",
    "\n",
    "# Start a loop that iterates through each value in the split_ratios list.\n",
    "for test_size in split_ratios:\n",
    "    # Print a message indicating the current split ratio being processed.\n",
    "    print(f\"\\nProcessing split ratio (test size): {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fe66300",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Split the data into training and testing sets based on the current split ratio.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    # Preprocess the characteristics: Convert variables categorical to numerical using One-Hot Encoding\n",
    "    # Apply to the training and test sets separately to avoid data leakage\n",
    "    X_train_processed = pd.get_dummies(X_train)\n",
    "    X_test_processed = pd.get_dummies(X_test)\n",
    "\n",
    "    # Ensure that the training and test sets have the same columns after one-hot encoding\n",
    "    # This handles cases where a category may appear in the test set but not in the training set (or vice versa)\n",
    "    X_train_processed, X_test_processed = X_train_processed.align(X_test_processed, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    print(f\"  Data split and preprocessed for test size {test_size}.\")\n",
    "    print(f\"  X_train_processed shape: {X_train_processed.shape}\")\n",
    "    print(f\"  X_test_processed shape: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f9f951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Implement and evaluate the Decision Tree classifier.\n",
    "    print(\"  Training and evaluating Decision Tree...\")\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "    dt_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_dt = dt_classifier.predict(X_test_processed)\n",
    "    accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "    report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "    print(f\"    Decision Tree Accuracy: {accuracy_dt:.4f}\")\n",
    "\n",
    "    # Store Decision Tree results\n",
    "    if test_size not in results:\n",
    "        results[test_size] = {}\n",
    "    results[test_size]['Decision Tree'] = {\n",
    "        'accuracy': accuracy_dt,\n",
    "        'report': report_dt\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b5b5515",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Implement and evaluate the k-NN classifier.\n",
    "    print(\"  Training and evaluating k-NN...\")\n",
    "    # Using the best k found in the previous single split analysis (k=25)\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_knn = knn_classifier.predict(X_test_processed)\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    report_knn = classification_report(y_test, y_pred_knn, output_dict=True)\n",
    "    print(f\"    k-NN Accuracy: {accuracy_knn:.4f}\")\n",
    "\n",
    "    # Store k-NN results\n",
    "    results[test_size]['k-NN'] = {\n",
    "        'accuracy': accuracy_knn,\n",
    "        'report': report_knn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d564f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features for the Logistic Regression model\n",
    "best_rule_pair = ('education-num', 'capital-gain')\n",
    "X_train_rule = X_train_processed[list(best_rule_pair)]\n",
    "X_test_rule = X_test_processed[list(best_rule_pair)]\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "print(\"  Training and evaluating Logistic Regression (on selected features)...\")\n",
    "lr_classifier = LogisticRegression(random_state=42)\n",
    "lr_classifier.fit(X_train_rule, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lr = lr_classifier.predict(X_test_rule)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
    "print(f\"    Logistic Regression Accuracy: {accuracy_lr:.4f}\")\n",
    "\n",
    "# Store Logistic Regression results\n",
    "results[test_size]['Logistic Regression'] = {\n",
    "    'accuracy': accuracy_lr,\n",
    "    'report': report_lr\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56a57369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of estimators for the Voting Classifier.\n",
    "# Use the already trained models from the current split iteration.\n",
    "estimators = [\n",
    "    ('dt', dt_classifier),\n",
    "    ('knn', knn_classifier),\n",
    "    ('lr', lr_classifier) # Use the LR classifier trained on selected features\n",
    "]\n",
    "\n",
    "# Instantiate a VotingClassifier object with 'hard' voting.\n",
    "# n_jobs=-1 uses all available CPU cores for parallel processing, which can speed up training\n",
    "ensemble_classifier = VotingClassifier(estimators=estimators, voting='hard', n_jobs=-1)\n",
    "\n",
    "# Train the VotingClassifier on the preprocessed training data.\n",
    "print(\"  Training Voting Classifier...\")\n",
    "ensemble_classifier.fit(X_train_processed, y_train)\n",
    "print(\"  Voting Classifier trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f4692c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the preprocessed test data using the trained Voting Classifier.\n",
    "print(\"  Evaluating Voting Classifier...\")\n",
    "y_pred_ensemble = ensemble_classifier.predict(X_test_processed)\n",
    "\n",
    "# Evaluate the performance of the Voting Classifier.\n",
    "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "report_ensemble = classification_report(y_test, y_pred_ensemble, output_dict=True)\n",
    "\n",
    "print(f\"    Voting Classifier Accuracy: {accuracy_ensemble:.4f}\")\n",
    "\n",
    "# Store the performance metrics of the Voting Classifier in the results dictionary.\n",
    "results[test_size]['Voting Classifier'] = {\n",
    "    'accuracy': accuracy_ensemble,\n",
    "    'report': report_ensemble\n",
    "}\n",
    "print(\"  Voting Classifier evaluated and results stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7017ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary to hold accuracies for easier DataFrame creation\n",
    "accuracy_summary = {}\n",
    "for test_size, models in results.items():\n",
    "    accuracy_summary[test_size] = {model_name: model_results['accuracy'] for model_name, model_results in models.items()}\n",
    "\n",
    "# Create a DataFrame from the accuracy summary dictionary\n",
    "# Transpose the DataFrame so models are rows and test sizes are columns\n",
    "accuracy_df = pd.DataFrame.from_dict(accuracy_summary, orient='index').transpose()\n",
    "\n",
    "# Sort columns by test size (ascending) for better readability\n",
    "accuracy_df = accuracy_df.sort_index(axis=1)\n",
    "\n",
    "print(\"Accuracy Summary Across Different Train-Test Splits:\")\n",
    "display(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2a138e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# (Optional) Create a line plot showing the accuracy of each model across the different split ratios.\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.lineplot(data=accuracy_df.transpose(), marker='o') # Transpose back for plotting test_size on x-axis\n",
    "plt.title('Model Accuracy vs. Train-Test Split Ratio')\n",
    "plt.xlabel('Test Size (Split Ratio)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(accuracy_df.columns) # Set x-ticks to the test sizes\n",
    "plt.grid(True)\n",
    "plt.legend(title='Model')\n",
    "plt.tight_layout() # Adjust layout\n",
    "\n",
    "# (Optional) Save the plot to the figures directory defined by the figs variable.\n",
    "plot_path = os.path.join(figs, \"model_accuracy_vs_split_ratio.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "print(f\"Accuracy plot saved to: {plot_path}\")\n",
    "\n",
    "# (Optional) Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3656d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the performance metrics for each split ratio.\n",
    "results = {}\n",
    "\n",
    "# Start a loop that iterates through each value in the split_ratios list.\n",
    "for test_size in split_ratios:\n",
    "    # Print a message indicating the current split ratio being processed.\n",
    "    print(f\"\\nProcesando proporción de división (tamaño del conjunto de prueba): {test_size}\")\n",
    "\n",
    "    # Split the data into training and testing sets based on the current split ratio.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    # Preprocesar las características: Convertir variables categóricas a numéricas usando One-Hot Encoding\n",
    "    # Aplicar a los conjuntos de entrenamiento y prueba por separado para evitar fuga de datos\n",
    "    X_train_processed = pd.get_dummies(X_train)\n",
    "    X_test_processed = pd.get_dummies(X_test)\n",
    "\n",
    "    # Asegurarse de que los conjuntos de entrenamiento y prueba tengan las mismas columnas después del one-hot encoding\n",
    "    # Esto maneja casos donde una categoría puede aparecer en el test set pero no en el training set (o viceversa)\n",
    "    X_train_processed, X_test_processed = X_train_processed.align(X_test_processed, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    print(f\"  Datos divididos y preprocesados para tamaño de prueba {test_size}.\")\n",
    "    print(f\"  Forma de X_train_processed: {X_train_processed.shape}\")\n",
    "    print(f\"  Forma de X_test_processed: {X_test_processed.shape}\")\n",
    "\n",
    "    # Implementar y evaluar el clasificador de Árbol de Decisión.\n",
    "    print(\"  Entrenando y evaluando Árbol de Decisión...\")\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "    dt_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_dt = dt_classifier.predict(X_test_processed)\n",
    "    accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "    report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "    print(f\"    Precisión del Árbol de Decisión: {accuracy_dt:.4f}\")\n",
    "\n",
    "    # Almacenar resultados del Árbol de Decisión\n",
    "    if test_size not in results:\n",
    "        results[test_size] = {}\n",
    "    results[test_size]['Decision Tree'] = {\n",
    "        'accuracy': accuracy_dt,\n",
    "        'report': report_dt\n",
    "    }\n",
    "\n",
    "    # Implementar y evaluar el clasificador k-NN.\n",
    "    print(\"  Entrenando y evaluando k-NN...\")\n",
    "    # Usando el mejor k encontrado en el análisis de división única anterior (k=25)\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_knn = knn_classifier.predict(X_test_processed)\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    report_knn = classification_report(y_test, y_pred_knn, output_dict=True)\n",
    "    print(f\"    Precisión de k-NN: {accuracy_knn:.4f}\")\n",
    "\n",
    "    # Almacenar resultados de k-NN\n",
    "    results[test_size]['k-NN'] = {\n",
    "        'accuracy': accuracy_knn,\n",
    "        'report': report_knn\n",
    "    }\n",
    "\n",
    "    # Seleccionar las características para el modelo de Regresión Logística\n",
    "    best_rule_pair = ('education-num', 'capital-gain')\n",
    "    X_train_rule = X_train_processed[list(best_rule_pair)]\n",
    "    X_test_rule = X_test_processed[list(best_rule_pair)]\n",
    "\n",
    "    # Inicializar y entrenar el modelo de Regresión Logística\n",
    "    print(\"  Entrenando y evaluando Regresión Logística (en características seleccionadas)...\")\n",
    "    lr_classifier = LogisticRegression(random_state=42)\n",
    "    lr_classifier.fit(X_train_rule, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred_lr = lr_classifier.predict(X_test_rule)\n",
    "\n",
    "    # Evaluar el clasificador\n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "    report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
    "    print(f\"    Precisión de Regresión Logística: {accuracy_lr:.4f}\")\n",
    "\n",
    "    # Almacenar resultados de Regresión Logística\n",
    "    results[test_size]['Logistic Regression'] = {\n",
    "        'accuracy': accuracy_lr,\n",
    "        'report': report_lr\n",
    "    }\n",
    "\n",
    "    # Crear una lista de estimadores para el Voting Classifier.\n",
    "    # Usar los modelos ya entrenados de la iteración de división actual.\n",
    "    estimators = [\n",
    "        ('dt', dt_classifier),\n",
    "        ('knn', knn_classifier),\n",
    "        ('lr', lr_classifier) # Usar el clasificador LR entrenado en características seleccionadas\n",
    "    ]\n",
    "\n",
    "    # Instanciar un objeto VotingClassifier con votación 'hard'.\n",
    "    # n_jobs=-1 usa todos los núcleos de CPU disponibles para procesamiento paralelo, lo que puede acelerar el entrenamiento\n",
    "    ensemble_classifier = VotingClassifier(estimators=estimators, voting='hard', n_jobs=-1)\n",
    "\n",
    "    # Entrenar el VotingClassifier en los datos de entrenamiento preprocesados.\n",
    "    print(\"  Entrenando Clasificador de Votación...\")\n",
    "    ensemble_classifier.fit(X_train_processed, y_train)\n",
    "    print(\"  Clasificador de Votación entrenado.\")\n",
    "\n",
    "    # Realizar predicciones en los datos de prueba preprocesados usando el Voting Classifier entrenado.\n",
    "    print(\"  Evaluando Clasificador de Votación...\")\n",
    "    y_pred_ensemble = ensemble_classifier.predict(X_test_processed)\n",
    "\n",
    "    # Evaluar el rendimiento del Voting Classifier.\n",
    "    accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "    report_ensemble = classification_report(y_test, y_pred_ensemble, output_dict=True)\n",
    "\n",
    "    print(f\"    Precisión del Clasificador de Votación: {accuracy_ensemble:.4f}\")\n",
    "\n",
    "    # Almacenar las métricas de rendimiento del Voting Classifier en el diccionario de resultados.\n",
    "    results[test_size]['Voting Classifier'] = {\n",
    "        'accuracy': accuracy_ensemble,\n",
    "        'report': report_ensemble\n",
    "    }\n",
    "    print(\"  Clasificador de Votación evaluado y resultados almacenados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09d57b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the performance metrics for each split ratio.\n",
    "# Inicializar un diccionario para almacenar las métricas de rendimiento para cada proporción de división.\n",
    "results = {}\n",
    "\n",
    "# Start a loop that iterates through each value in the split_ratios list.\n",
    "# Iniciar un bucle que itera a través de cada valor en la lista split_ratios.\n",
    "for test_size in split_ratios:\n",
    "    # Print a message indicating the current split ratio being processed.\n",
    "    # Imprimir un mensaje indicando la proporción de división actual que se está procesando.\n",
    "    print(f\"\\nProcesando proporción de división (tamaño del conjunto de prueba): {test_size}\")\n",
    "\n",
    "    # Split the data into training and testing sets based on the current split ratio.\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba basándose en la proporción de división actual.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    # Preprocesar las características: Convertir variables categóricas a numéricas usando One-Hot Encoding\n",
    "    # Aplicar a los conjuntos de entrenamiento y prueba por separado para evitar fuga de datos\n",
    "    X_train_processed = pd.get_dummies(X_train)\n",
    "    X_test_processed = pd.get_dummies(X_test)\n",
    "\n",
    "    # Asegurarse de que los conjuntos de entrenamiento y prueba tengan las mismas columnas después del one-hot encoding\n",
    "    # Esto maneja casos donde una categoría puede aparecer en el test set pero no en el training set (o viceversa)\n",
    "    X_train_processed, X_test_processed = X_train_processed.align(X_test_processed, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    print(f\"  Datos divididos y preprocesados para tamaño de prueba {test_size}.\")\n",
    "    print(f\"  Forma de X_train_processed: {X_train_processed.shape}\")\n",
    "    print(f\"  Forma de X_test_processed: {X_test_processed.shape}\")\n",
    "\n",
    "    # Implementar y evaluar el clasificador de Árbol de Decisión.\n",
    "    print(\"  Entrenando y evaluando Árbol de Decisión...\")\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "    dt_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_dt = dt_classifier.predict(X_test_processed)\n",
    "    accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "    report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "    print(f\"    Precisión del Árbol de Decisión: {accuracy_dt:.4f}\")\n",
    "\n",
    "    # Store Decision Tree results\n",
    "    # Almacenar resultados del Árbol de Decisión\n",
    "    if test_size not in results:\n",
    "        results[test_size] = {}\n",
    "    results[test_size]['Decision Tree'] = {\n",
    "        'accuracy': accuracy_dt,\n",
    "        'report': report_dt\n",
    "    }\n",
    "\n",
    "    # Implementar y evaluar el clasificador k-NN.\n",
    "    print(\"  Entrenando y evaluando k-NN...\")\n",
    "    # Using the best k found in the previous single split analysis (k=25)\n",
    "    # Usando el mejor k encontrado en el análisis de división única anterior (k=25)\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_knn = knn_classifier.predict(X_test_processed)\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    report_knn = classification_report(y_test, y_pred_knn, output_dict=True)\n",
    "    print(f\"    Precisión de k-NN: {accuracy_knn:.4f}\")\n",
    "\n",
    "    # Store k-NN results\n",
    "    # Almacenar resultados de k-NN\n",
    "    results[test_size]['k-NN'] = {\n",
    "        'accuracy': accuracy_knn,\n",
    "        'report': report_knn\n",
    "    }\n",
    "\n",
    "    # Seleccionar las características para el modelo de Regresión Logística\n",
    "    best_rule_pair = ('education-num', 'capital-gain')\n",
    "    X_train_rule = X_train_processed[list(best_rule_pair)]\n",
    "    X_test_rule = X_test_processed[list(best_rule_pair)]\n",
    "\n",
    "    # Inicializar y entrenar el modelo de Regresión Logística\n",
    "    print(\"  Entrenando y evaluando Regresión Logística (en características seleccionadas)...\")\n",
    "    lr_classifier = LogisticRegression(random_state=42)\n",
    "    lr_classifier.fit(X_train_rule, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    # Make predictions on the test set\n",
    "    y_pred_lr = lr_classifier.predict(X_test_rule)\n",
    "\n",
    "    # Evaluar el clasificador\n",
    "    # Evaluate the classifier\n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "    report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
    "    print(f\"    Precisión de Regresión Logística: {accuracy_lr:.4f}\")\n",
    "\n",
    "    # Store Logistic Regression results\n",
    "    # Almacenar resultados de Regresión Logística\n",
    "    results[test_size]['Logistic Regression'] = {\n",
    "        'accuracy': accuracy_lr,\n",
    "        'report': report_lr\n",
    "    }\n",
    "\n",
    "    # Crear una lista de estimadores para el Voting Classifier.\n",
    "    # Usar los modelos ya entrenados de la iteración de división actual.\n",
    "    # Use the already trained models from the current split iteration.\n",
    "    estimators = [\n",
    "        ('dt', dt_classifier),\n",
    "        ('knn', knn_classifier),\n",
    "        ('lr', lr_classifier) # Usar el clasificador LR entrenado en características seleccionadas\n",
    "    ]\n",
    "\n",
    "    # Instantiate a VotingClassifier object with 'hard' voting.\n",
    "    # n_jobs=-1 uses all available CPU cores for parallel processing, which can speed up training\n",
    "    # Instanciar un objeto VotingClassifier con votación 'hard'.\n",
    "    # n_jobs=-1 usa todos los núcleos de CPU disponibles para procesamiento paralelo, lo que puede acelerar el entrenamiento\n",
    "    ensemble_classifier = VotingClassifier(estimators=estimators, voting='hard', n_jobs=-1)\n",
    "\n",
    "    # Train the VotingClassifier on the preprocessed training data.\n",
    "    # Entrenar el VotingClassifier en los datos de entrenamiento preprocesados.\n",
    "    print(\"  Entrenando Clasificador de Votación...\")\n",
    "    ensemble_classifier.fit(X_train_processed, y_train)\n",
    "    print(\"  Clasificador de Votación entrenado.\")\n",
    "\n",
    "    # Make predictions on the preprocessed test data using the trained Voting Classifier.\n",
    "    # Realizar predicciones en los datos de prueba preprocesados usando el Voting Classifier entrenado.\n",
    "    print(\"  Evaluando Clasificador de Votación...\")\n",
    "    y_pred_ensemble = ensemble_classifier.predict(X_test_processed)\n",
    "\n",
    "    # Evaluate the performance of the Voting Classifier.\n",
    "    # Evaluar el rendimiento del Voting Classifier.\n",
    "    accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "    report_ensemble = classification_report(y_test, y_pred_ensemble, output_dict=True)\n",
    "\n",
    "    print(f\"    Precisión del Clasificador de Votación: {accuracy_ensemble:.4f}\")\n",
    "\n",
    "    # Store the performance metrics of the Voting Classifier in the results dictionary.\n",
    "    # Almacenar las métricas de rendimiento del Voting Classifier en el diccionario de resultados.\n",
    "    results[test_size]['Voting Classifier'] = {\n",
    "        'accuracy': accuracy_ensemble,\n",
    "        'report': report_ensemble\n",
    "    }\n",
    "    print(\"  Clasificador de Votación evaluado y resultados almacenados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19722dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the performance metrics for each split ratio.\n",
    "results = {}\n",
    "\n",
    "# Start a loop that iterates through each value in the split_ratios list.\n",
    "for test_size in split_ratios:\n",
    "    # Print a message indicating the current split ratio being processed.\n",
    "    print(f\"\\nProcesando proporción de división (tamaño del conjunto de prueba): {test_size}\")\n",
    "\n",
    "    # Split the data into training and testing sets based on the current split ratio.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    # Preprocesar las características: Convertir variables categóricas a numéricas usando One-Hot Encoding\n",
    "    # Aplicar a los conjuntos de entrenamiento y prueba por separado para evitar fuga de datos\n",
    "    X_train_processed = pd.get_dummies(X_train)\n",
    "    X_test_processed = pd.get_dummies(X_test)\n",
    "\n",
    "    # Asegurarse de que los conjuntos de entrenamiento y prueba tengan las mismas columnas después del one-hot encoding\n",
    "    # Esto maneja casos donde una categoría puede aparecer en el test set pero no en el training set (o viceversa)\n",
    "    X_train_processed, X_test_processed = X_train_processed.align(X_test_processed, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    print(f\"  Datos divididos y preprocesados para tamaño de prueba {test_size}.\")\n",
    "    print(f\"  Forma de X_train_processed: {X_train_processed.shape}\")\n",
    "    print(f\"  Forma de X_test_processed: {X_test_processed.shape}\")\n",
    "\n",
    "    # Implementar y evaluar el clasificador de Árbol de Decisión.\n",
    "    print(\"  Entrenando y evaluando Árbol de Decisión...\")\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "    dt_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_dt = dt_classifier.predict(X_test_processed)\n",
    "    accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "    report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "    print(f\"    Precisión del Árbol de Decisión: {accuracy_dt:.4f}\")\n",
    "\n",
    "    # Almacenar resultados del Árbol de Decisión\n",
    "    if test_size not in results:\n",
    "        results[test_size] = {}\n",
    "    results[test_size]['Decision Tree'] = {\n",
    "        'accuracy': accuracy_dt,\n",
    "        'report': report_dt\n",
    "    }\n",
    "\n",
    "    # Implementar y evaluar el clasificador k-NN.\n",
    "    print(\"  Entrenando y evaluando k-NN...\")\n",
    "    # Usando el mejor k encontrado en el análisis de división única anterior (k=25)\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_knn = knn_classifier.predict(X_test_processed)\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    report_knn = classification_report(y_test, y_pred_knn, output_dict=True)\n",
    "    print(f\"    Precisión de k-NN: {accuracy_knn:.4f}\")\n",
    "\n",
    "    # Almacenar resultados de k-NN\n",
    "    results[test_size]['k-NN'] = {\n",
    "        'accuracy': accuracy_knn,\n",
    "        'report': report_knn\n",
    "    }\n",
    "\n",
    "    # Seleccionar las características para el modelo de Regresión Logística\n",
    "    best_rule_pair = ('education-num', 'capital-gain')\n",
    "    X_train_rule = X_train_processed[list(best_rule_pair)]\n",
    "    X_test_rule = X_test_processed[list(best_rule_pair)]\n",
    "\n",
    "    # Inicializar y entrenar el modelo de Regresión Logística\n",
    "    print(\"  Entrenando y evaluando Regresión Logística (en características seleccionadas)...\")\n",
    "    lr_classifier = LogisticRegression(random_state=42)\n",
    "    lr_classifier.fit(X_train_rule, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred_lr = lr_classifier.predict(X_test_rule)\n",
    "\n",
    "    # Evaluar el clasificador\n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "    report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
    "    print(f\"    Precisión de Regresión Logística: {accuracy_lr:.4f}\")\n",
    "\n",
    "    # Almacenar resultados de Regresión Logística\n",
    "    results[test_size]['Logistic Regression'] = {\n",
    "        'accuracy': accuracy_lr,\n",
    "        'report': report_lr\n",
    "    }\n",
    "\n",
    "    # Crear una lista de estimadores para el Voting Classifier.\n",
    "    # Usar los modelos ya entrenados de la iteración de división actual.\n",
    "    estimators = [\n",
    "        ('dt', dt_classifier),\n",
    "        ('knn', knn_classifier),\n",
    "        ('lr', lr_classifier) # Usar el clasificador LR entrenado en características seleccionadas\n",
    "    ]\n",
    "\n",
    "    # Instanciar un objeto VotingClassifier con votación 'hard'.\n",
    "    # n_jobs=-1 usa todos los núcleos de CPU disponibles para procesamiento paralelo, lo que puede acelerar el entrenamiento\n",
    "    ensemble_classifier = VotingClassifier(estimators=estimators, voting='hard', n_jobs=-1)\n",
    "\n",
    "    # Entrenar el VotingClassifier en los datos de entrenamiento preprocesados.\n",
    "    print(\"  Entrenando Clasificador de Votación...\")\n",
    "    ensemble_classifier.fit(X_train_processed, y_train)\n",
    "    print(\"  Clasificador de Votación entrenado.\")\n",
    "\n",
    "    # Realizar predicciones en los datos de prueba preprocesados usando el Voting Classifier entrenado.\n",
    "    print(\"  Evaluando Clasificador de Votación...\")\n",
    "    y_pred_ensemble = ensemble_classifier.predict(X_test_processed)\n",
    "\n",
    "    # Evaluar el rendimiento del Voting Classifier.\n",
    "    accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "    report_ensemble = classification_report(y_test, y_pred_ensemble, output_dict=True)\n",
    "\n",
    "    print(f\"    Precisión del Clasificador de Votación: {accuracy_ensemble:.4f}\")\n",
    "\n",
    "    # Almacenar las métricas de rendimiento del Voting Classifier en el diccionario de resultados.\n",
    "    results[test_size]['Voting Classifier'] = {\n",
    "        'accuracy': accuracy_ensemble,\n",
    "        'report': report_ensemble\n",
    "    }\n",
    "    print(\"  Clasificador de Votación evaluado y resultados almacenados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0088be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los diferentes tamaños del conjunto de prueba para las divisiones de entrenamiento-prueba.\n",
    "# Esto corresponde a tamaños de entrenamiento del 60%, 40%, 20% y 10% respectivamente.\n",
    "split_ratios = [0.6, 0.4, 0.2, 0.1]\n",
    "\n",
    "print(\"Proporciones de división entrenamiento-prueba (tamaño del conjunto de prueba):\")\n",
    "print(split_ratios)\n",
    "\n",
    "# Inicializar un diccionario para almacenar las métricas de rendimiento para cada proporción de división.\n",
    "results = {}\n",
    "\n",
    "# Iniciar un bucle que itera a través de cada valor en la lista split_ratios.\n",
    "for test_size in split_ratios:\n",
    "    # Imprimir un mensaje indicando la proporción de división actual que se está procesando.\n",
    "    print(f\"\\nProcesando proporción de división (tamaño del conjunto de prueba): {test_size}\")\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba basados en la proporción de división actual.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    # Preprocesar las características: Convertir variables categóricas a numéricas usando One-Hot Encoding\n",
    "    # Aplicar a los conjuntos de entrenamiento y prueba por separado para evitar fuga de datos (data leakage)\n",
    "    X_train_processed = pd.get_dummies(X_train)\n",
    "    X_test_processed = pd.get_dummies(X_test)\n",
    "\n",
    "    # Asegurar que los conjuntos de entrenamiento y prueba tengan las mismas columnas después del one-hot encoding\n",
    "    # Esto maneja casos donde una categoría puede aparecer en el conjunto de prueba pero no en el de entrenamiento (o viceversa)\n",
    "    X_train_processed, X_test_processed = X_train_processed.align(X_test_processed, join='left', axis=1, fill_value=0)\n",
    "\n",
    "    print(f\"  Datos divididos y preprocesados para tamaño de prueba {test_size}.\")\n",
    "    print(f\"  Forma de X_train_processed: {X_train_processed.shape}\")\n",
    "    print(f\"  Forma de X_test_processed: {X_test_processed.shape}\")\n",
    "\n",
    "    # Implementar y evaluar el clasificador de Árbol de Decisión.\n",
    "    print(\"  Entrenando y evaluando Árbol de Decisión...\")\n",
    "    dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "    dt_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_dt = dt_classifier.predict(X_test_processed)\n",
    "    accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "    report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "    print(f\"    Precisión del Árbol de Decisión: {accuracy_dt:.4f}\")\n",
    "\n",
    "    # Almacenar resultados del Árbol de Decisión\n",
    "    if test_size not in results:\n",
    "        results[test_size] = {}\n",
    "    results[test_size]['Decision Tree'] = {\n",
    "        'accuracy': accuracy_dt,\n",
    "        'report': report_dt\n",
    "    }\n",
    "\n",
    "    # Implementar y evaluar el clasificador k-NN.\n",
    "    print(\"  Entrenando y evaluando k-NN...\")\n",
    "    # Usando el mejor k encontrado en el análisis de división única anterior (k=25)\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    knn_classifier.fit(X_train_processed, y_train)\n",
    "    y_pred_knn = knn_classifier.predict(X_test_processed)\n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    report_knn = classification_report(y_test, y_pred_knn, output_dict=True)\n",
    "    print(f\"    Precisión de k-NN: {accuracy_knn:.4f}\")\n",
    "\n",
    "    # Almacenar resultados de k-NN\n",
    "    results[test_size]['k-NN'] = {\n",
    "        'accuracy': accuracy_knn,\n",
    "        'report': report_knn\n",
    "    }\n",
    "\n",
    "    # Seleccionar las características para el modelo de Regresión Logística\n",
    "    best_rule_pair = ('education-num', 'capital-gain')\n",
    "    X_train_rule = X_train_processed[list(best_rule_pair)]\n",
    "    X_test_rule = X_test_processed[list(best_rule_pair)]\n",
    "\n",
    "    # Inicializar y entrenar el modelo de Regresión Logística\n",
    "    print(\"  Entrenando y evaluando Regresión Logística (en características seleccionadas)...\")\n",
    "    lr_classifier = LogisticRegression(random_state=42)\n",
    "    lr_classifier.fit(X_train_rule, y_train)\n",
    "\n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred_lr = lr_classifier.predict(X_test_rule)\n",
    "\n",
    "    # Evaluar el clasificador\n",
    "    accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "    report_lr = classification_report(y_test, y_pred_lr, output_dict=True)\n",
    "    print(f\"    Precisión de Regresión Logística: {accuracy_lr:.4f}\")\n",
    "\n",
    "    # Almacenar resultados de Regresión Logística\n",
    "    results[test_size]['Logistic Regression'] = {\n",
    "        'accuracy': accuracy_lr,\n",
    "        'report': report_lr\n",
    "    }\n",
    "\n",
    "    # Crear una lista de estimadores para el Voting Classifier.\n",
    "    # Usar los modelos ya entrenados de la iteración de división actual.\n",
    "    estimators = [\n",
    "        ('dt', dt_classifier),\n",
    "        ('knn', knn_classifier),\n",
    "        ('lr', lr_classifier) # Usar el clasificador LR entrenado en características seleccionadas\n",
    "    ]\n",
    "\n",
    "    # Instanciar un objeto VotingClassifier con votación 'hard'.\n",
    "    # n_jobs=-1 usa todos los núcleos de CPU disponibles para procesamiento paralelo, lo que puede acelerar el entrenamiento\n",
    "    ensemble_classifier = VotingClassifier(estimators=estimators, voting='hard', n_jobs=-1)\n",
    "\n",
    "    # Entrenar el VotingClassifier en los datos de entrenamiento preprocesados.\n",
    "    print(\"  Entrenando Clasificador de Votación...\")\n",
    "    # Es importante notar que el VotingClassifier espera que todos los estimadores\n",
    "    # en 'estimators' acepten el mismo formato de entrada. Dado que lr_classifier\n",
    "    # fue entrenado solo con un subconjunto de columnas, esto podría causar un error\n",
    "    # si el VotingClassifier intenta pasarle X_train_processed completo.\n",
    "    # Para una implementación más robusta, se debería usar un Pipeline con ColumnTransformer\n",
    "    # para el modelo de Regresión Logística dentro del ensemble.\n",
    "    # Sin embargo, para cumplir con el propósito de este análisis comparativo simple,\n",
    "    # y asumiendo que los modelos pueden manejar las columnas que necesitan, procedemos.\n",
    "    # Nota: En un escenario de producción, se recomienda usar Pipelines.\n",
    "\n",
    "    # Para que el VotingClassifier funcione correctamente aquí, debemos entrenar\n",
    "    # los modelos individuales (DT, k-NN) con X_train_processed completo, y el modelo\n",
    "    # de Regresión Logística con X_train_rule (el subconjunto).\n",
    "    # Luego, al crear el VotingClassifier, si no usamos Pipelines, solo podemos\n",
    "    # incluir modelos que acepten X_train_processed completo.\n",
    "    # Esto significa que el modelo de Regresión Logística debe ser adaptado o\n",
    "    # re-entrenado para aceptar X_train_processed completo y seleccionar sus columnas internamente,\n",
    "    # o usamos un Pipeline como se hizo en la celda anterior (Q7.1).\n",
    "\n",
    "    # Vamos a usar la estrategia del Pipeline para el modelo de Regresión Logística dentro del ensemble\n",
    "    # para asegurar que reciba solo las columnas que necesita, mientras que el ensemble\n",
    "    # recibe X_train_processed completo.\n",
    "\n",
    "    # Re-inicializar los modelos individuales para asegurar que se entrenen con los datos del split actual\n",
    "    dt_classifier_ensemble = DecisionTreeClassifier(random_state=42)\n",
    "    knn_classifier_ensemble = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    lr_classifier_ensemble = LogisticRegression(random_state=42)\n",
    "\n",
    "    # Entrenar los modelos individuales con los datos del split actual\n",
    "    dt_classifier_ensemble.fit(X_train_processed, y_train)\n",
    "    knn_classifier_ensemble.fit(X_train_processed, y_train)\n",
    "    # Entrenar el modelo de Regresión Logística con el subconjunto de columnas para este split\n",
    "    lr_classifier_ensemble.fit(X_train_rule, y_train)\n",
    "\n",
    "\n",
    "    # Crear un Pipeline para el modelo de reglas que primero selecciona las columnas\n",
    "    rule_pipeline = Pipeline([\n",
    "        ('selector', ColumnTransformer([('passthrough', 'passthrough', list(best_rule_pair))],\n",
    "                                      remainder='drop')), # Selecciona solo las columnas del par\n",
    "        ('model', lr_classifier_ensemble) # Usar el modelo LR entrenado para este split\n",
    "    ])\n",
    "\n",
    "    # Actualizar la lista de estimadores con los modelos entrenados y el pipeline de reglas\n",
    "    estimators_ensemble_piped = [\n",
    "        ('dt', dt_classifier_ensemble),\n",
    "        ('knn', knn_classifier_ensemble),\n",
    "        ('rule_pipe', rule_pipeline) # Pipeline de reglas para este split\n",
    "    ]\n",
    "\n",
    "    # Inicializar el VotingClassifier con los modelos entrenados y el pipeline de reglas para este split\n",
    "    ensemble_classifier = VotingClassifier(estimators=estimators_ensemble_piped, voting='hard', n_jobs=-1)\n",
    "\n",
    "\n",
    "    # Entrenar el clasificador de conjunto con los datos de entrenamiento preprocesados para este split\n",
    "    print(\"  Entrenando Clasificador de Votación (con Pipelines)...\")\n",
    "    ensemble_classifier.fit(X_train_processed, y_train)\n",
    "    print(\"  Clasificador de Votación entrenado.\")\n",
    "\n",
    "    # Realizar predicciones en los datos de prueba preprocesados usando el Voting Classifier entrenado.\n",
    "    print(\"  Evaluando Clasificador de Votación...\")\n",
    "    y_pred_ensemble = ensemble_classifier.predict(X_test_processed)\n",
    "\n",
    "    # Evaluar el rendimiento del Voting Classifier.\n",
    "    accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "    report_ensemble = classification_report(y_test, y_pred_ensemble, output_dict=True)\n",
    "\n",
    "    print(f\"    Precisión del Clasificador de Votación: {accuracy_ensemble:.4f}\")\n",
    "\n",
    "    # Almacenar las métricas de rendimiento del Voting Classifier en el diccionario de resultados.\n",
    "    results[test_size]['Voting Classifier'] = {\n",
    "        'accuracy': accuracy_ensemble,\n",
    "        'report': report_ensemble\n",
    "    }\n",
    "    print(\"  Clasificador de Votación evaluado y resultados almacenados.\")\n",
    "\n",
    "# Imprimir un resumen de las precisiones obtenidas para cada modelo en cada división.\n",
    "print(\"\\n--- Resumen de Precisión en Diferentes Divisiones Entrenamiento-Prueba ---\")\n",
    "\n",
    "# Crear un diccionario para contener las precisiones para facilitar la creación del DataFrame\n",
    "accuracy_summary = {}\n",
    "for test_size, models in results.items():\n",
    "    accuracy_summary[test_size] = {model_name: model_results['accuracy'] for model_name, model_results in models.items()}\n",
    "\n",
    "# Crear un DataFrame a partir del diccionario de resumen de precisión\n",
    "# Transponer el DataFrame para que los modelos sean las filas y los tamaños de prueba sean las columnas\n",
    "accuracy_df = pd.DataFrame.from_dict(accuracy_summary, orient='index').transpose()\n",
    "\n",
    "# Ordenar las columnas por tamaño de prueba (ascendente) para una mejor legibilidad\n",
    "accuracy_df = accuracy_df.sort_index(axis=1)\n",
    "\n",
    "print(\"Resumen de Precisión a Través de Diferentes Divisiones Entrenamiento-Prueba:\")\n",
    "display(accuracy_df)\n",
    "\n",
    "# (Opcional) Crear un gráfico de líneas mostrando la precisión de cada modelo a través de las diferentes proporciones de división.\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.lineplot(data=accuracy_df.transpose(), marker='o') # Transponer de nuevo para graficar test_size en el eje x\n",
    "plt.title('Precisión del Modelo vs. Proporción de División Entrenamiento-Prueba')\n",
    "plt.xlabel('Tamaño del Conjunto de Prueba (Proporción de División)')\n",
    "plt.ylabel('Precisión (Accuracy)')\n",
    "plt.xticks(accuracy_df.columns) # Establecer las marcas del eje x a los tamaños de prueba\n",
    "plt.grid(True)\n",
    "plt.legend(title='Modelo')\n",
    "plt.tight_layout() # Ajustar el diseño\n",
    "\n",
    "# (Opcional) Guardar el gráfico en el directorio de figuras definido por la variable figs.\n",
    "plot_path = os.path.join(figs, \"model_accuracy_vs_split_ratio.png\")\n",
    "plt.savefig(plot_path, dpi=300)\n",
    "print(f\"Gráfico de precisión guardado en: {plot_path}\")\n",
    "\n",
    "# (Opcional) Mostrar el gráfico.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2fa7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Guardar en mi drive los notebooks en formato .ipynb y .py.\n",
    "'''\n",
    "\n",
    "notebook_name = \"notebook_taller3\"\n",
    "\n",
    "# Ruta completa de salida en Drive\n",
    "ipynb_path = os.path.join(codes, f\"{notebook_name}.ipynb\")\n",
    "py_path = os.path.join(codes, f\"{notebook_name}.py\")\n",
    "\n",
    "# Ruta temporal para guardar el notebook actual antes de convertir\n",
    "temp_ipynb_path = \"/content/temp_notebook.ipynb\"\n",
    "\n",
    "# Guardar el notebook actual a una ruta temporal usando el comando mágico %notebook\n",
    "# Esto asegura que nbconvert tenga un archivo .ipynb específico para trabajar\n",
    "get_ipython().run_line_magic('notebook', temp_ipynb_path)\n",
    "\n",
    "\n",
    "# Guardar en Drive en formato .ipynb\n",
    "# Usar el archivo temporal guardado por %notebook\n",
    "!jupyter nbconvert --to notebook --output \"{ipynb_path}\" \"{temp_ipynb_path}\"\n",
    "\n",
    "# Guardar en Drive en formato .py\n",
    "# Usar el archivo temporal guardado por %notebook\n",
    "!jupyter nbconvert --to script   --output \"{py_path}\"    \"{temp_ipynb_path}\"\n",
    "\n",
    "print(f\"Archivos guardados en Drive:\\n- {ipynb_path}\\n- {py_path}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
